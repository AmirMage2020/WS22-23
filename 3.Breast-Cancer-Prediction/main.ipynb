{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape : (569, 33)\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'training set shape : {df.shape}')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)\n",
    "x = df.drop(['id', 'diagnosis'], axis=1)\n",
    "y = df.iloc[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, shuffle=True, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "Y_train = Y_train.replace('M', 0)\n",
    "Y_train = Y_train.replace('B', 1)\n",
    "y_train = torch.tensor(Y_train.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "Y_test = Y_test.replace('M', 0)\n",
    "Y_test = Y_test.replace('B', 1)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1.], requires_grad=True)\n",
      "tensor([[1.1540e+01, 1.4440e+01, 7.4650e+01,  ..., 6.9180e-02, 2.3290e-01,\n",
      "         8.1340e-02],\n",
      "        [1.2540e+01, 1.8070e+01, 7.9420e+01,  ..., 1.6350e-02, 2.2330e-01,\n",
      "         5.5210e-02],\n",
      "        [1.3160e+01, 2.0540e+01, 8.4060e+01,  ..., 4.1950e-02, 2.6870e-01,\n",
      "         7.4290e-02],\n",
      "        ...,\n",
      "        [1.3340e+01, 1.5860e+01, 8.6490e+01,  ..., 1.7080e-01, 3.5270e-01,\n",
      "         1.0160e-01],\n",
      "        [1.3000e+01, 2.0780e+01, 8.3510e+01,  ..., 6.2960e-02, 3.1960e-01,\n",
      "         6.4350e-02],\n",
      "        [1.0660e+01, 1.5150e+01, 6.7490e+01,  ..., 0.0000e+00, 2.7100e-01,\n",
      "         6.1640e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generates_batches(x, y, batch_size):\n",
    "    batches = []\n",
    "    num_batches = int(x.shape[0]/batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batches.append(\n",
    "                     (x[i*batch_size: (i+1)*batch_size], \n",
    "                      y[i*batch_size: (i+1)*batch_size])\n",
    "            )\n",
    "\n",
    "    if(num_batches * batch_size < x.shape[0]):\n",
    "        batches.append(\n",
    "            (x[num_batches*batch_size : x.shape[0]],\n",
    "                y[num_batches*batch_size : x.shape[0]])\n",
    "            \n",
    "        )\n",
    "    return batches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "train_set = generates_batches(x_train, y_train, 4)\n",
    "print(train_set.__len__())\n",
    "\n",
    "\n",
    "test_set = generates_batches(x_test, y_test, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(30, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = x.view(-1)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return \"feedforward\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import trainer\n",
    "\n",
    "model = feedforward()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "max_epochs = 100\n",
    "model_trainer = trainer(model, optimizer, loss_fn, train_set, test_set, max_epochs, model_name = model.model_name , when_to_stop=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train_loss : 1.4325 ,  val_loss : 2.2414\n",
      "epoch : 2, train_loss : 0.4197 ,  val_loss : 1.3561\n",
      "epoch : 3, train_loss : 0.3173 ,  val_loss : 0.5580\n",
      "epoch : 4, train_loss : 0.2978 ,  val_loss : 0.5476\n",
      "epoch : 5, train_loss : 0.2895 ,  val_loss : 0.5387\n",
      "epoch : 6, train_loss : 0.2842 ,  val_loss : 0.5337\n",
      "epoch : 7, train_loss : 0.2797 ,  val_loss : 0.5261\n",
      "epoch : 8, train_loss : 0.2757 ,  val_loss : 0.5202\n",
      "epoch : 9, train_loss : 0.2719 ,  val_loss : 0.5132\n",
      "epoch : 10, train_loss : 0.2674 ,  val_loss : 0.5050\n",
      "epoch : 11, train_loss : 0.2633 ,  val_loss : 0.4970\n",
      "epoch : 12, train_loss : 0.2595 ,  val_loss : 0.4894\n",
      "epoch : 13, train_loss : 0.2563 ,  val_loss : 0.4823\n",
      "epoch : 14, train_loss : 0.2538 ,  val_loss : 0.4757\n",
      "epoch : 15, train_loss : 0.2515 ,  val_loss : 0.4696\n",
      "epoch : 16, train_loss : 0.2490 ,  val_loss : 0.4632\n",
      "epoch : 17, train_loss : 0.2467 ,  val_loss : 0.4568\n",
      "epoch : 18, train_loss : 0.2449 ,  val_loss : 0.4510\n",
      "epoch : 19, train_loss : 0.2433 ,  val_loss : 0.4456\n",
      "epoch : 20, train_loss : 0.2421 ,  val_loss : 0.4407\n",
      "epoch : 21, train_loss : 0.2409 ,  val_loss : 0.4360\n",
      "epoch : 22, train_loss : 0.2399 ,  val_loss : 0.4315\n",
      "epoch : 23, train_loss : 0.2389 ,  val_loss : 0.4271\n",
      "epoch : 24, train_loss : 0.2381 ,  val_loss : 0.4230\n",
      "epoch : 25, train_loss : 0.2373 ,  val_loss : 0.4190\n",
      "epoch : 26, train_loss : 0.2366 ,  val_loss : 0.4153\n",
      "epoch : 27, train_loss : 0.2359 ,  val_loss : 0.4118\n",
      "epoch : 28, train_loss : 0.2354 ,  val_loss : 0.4085\n",
      "epoch : 29, train_loss : 0.2349 ,  val_loss : 0.4054\n",
      "epoch : 30, train_loss : 0.2344 ,  val_loss : 0.4025\n",
      "epoch : 31, train_loss : 0.2339 ,  val_loss : 0.3997\n",
      "epoch : 32, train_loss : 0.2337 ,  val_loss : 0.3973\n",
      "epoch : 33, train_loss : 0.2335 ,  val_loss : 0.3949\n",
      "epoch : 34, train_loss : 0.2332 ,  val_loss : 0.3926\n",
      "epoch : 35, train_loss : 0.2330 ,  val_loss : 0.3903\n",
      "epoch : 36, train_loss : 0.2328 ,  val_loss : 0.3882\n",
      "epoch : 37, train_loss : 0.2327 ,  val_loss : 0.3864\n",
      "epoch : 38, train_loss : 0.2326 ,  val_loss : 0.3845\n",
      "epoch : 39, train_loss : 0.2325 ,  val_loss : 0.3826\n",
      "epoch : 40, train_loss : 0.2322 ,  val_loss : 0.3806\n",
      "epoch : 41, train_loss : 0.2319 ,  val_loss : 0.3785\n",
      "epoch : 42, train_loss : 0.2316 ,  val_loss : 0.3767\n",
      "epoch : 43, train_loss : 0.2314 ,  val_loss : 0.3748\n",
      "epoch : 44, train_loss : 0.2310 ,  val_loss : 0.3730\n",
      "epoch : 45, train_loss : 0.2307 ,  val_loss : 0.3713\n",
      "epoch : 46, train_loss : 0.2304 ,  val_loss : 0.3697\n",
      "epoch : 47, train_loss : 0.2300 ,  val_loss : 0.3680\n",
      "epoch : 48, train_loss : 0.2295 ,  val_loss : 0.3661\n",
      "epoch : 49, train_loss : 0.2291 ,  val_loss : 0.3644\n",
      "epoch : 50, train_loss : 0.2287 ,  val_loss : 0.3627\n",
      "epoch : 51, train_loss : 0.2284 ,  val_loss : 0.3610\n",
      "epoch : 52, train_loss : 0.2280 ,  val_loss : 0.3592\n",
      "epoch : 53, train_loss : 0.2276 ,  val_loss : 0.3576\n",
      "epoch : 54, train_loss : 0.2272 ,  val_loss : 0.3557\n",
      "epoch : 55, train_loss : 0.2268 ,  val_loss : 0.3540\n",
      "epoch : 56, train_loss : 0.2265 ,  val_loss : 0.3524\n",
      "epoch : 57, train_loss : 0.2261 ,  val_loss : 0.3509\n",
      "epoch : 58, train_loss : 0.2258 ,  val_loss : 0.3495\n",
      "epoch : 59, train_loss : 0.2255 ,  val_loss : 0.3483\n",
      "epoch : 60, train_loss : 0.2252 ,  val_loss : 0.3471\n",
      "epoch : 61, train_loss : 0.2249 ,  val_loss : 0.3460\n",
      "epoch : 62, train_loss : 0.2246 ,  val_loss : 0.3449\n",
      "epoch : 63, train_loss : 0.2244 ,  val_loss : 0.3440\n",
      "epoch : 64, train_loss : 0.2241 ,  val_loss : 0.3431\n",
      "epoch : 65, train_loss : 0.2239 ,  val_loss : 0.3423\n",
      "epoch : 66, train_loss : 0.2237 ,  val_loss : 0.3415\n",
      "epoch : 67, train_loss : 0.2235 ,  val_loss : 0.3409\n",
      "epoch : 68, train_loss : 0.2233 ,  val_loss : 0.3403\n",
      "epoch : 69, train_loss : 0.2231 ,  val_loss : 0.3398\n",
      "epoch : 70, train_loss : 0.2229 ,  val_loss : 0.3392\n",
      "epoch : 71, train_loss : 0.2226 ,  val_loss : 0.3384\n",
      "epoch : 72, train_loss : 0.2224 ,  val_loss : 0.3378\n",
      "epoch : 73, train_loss : 0.2222 ,  val_loss : 0.3373\n",
      "epoch : 74, train_loss : 0.2219 ,  val_loss : 0.3366\n",
      "epoch : 75, train_loss : 0.2218 ,  val_loss : 0.3361\n",
      "epoch : 76, train_loss : 0.2215 ,  val_loss : 0.3354\n",
      "epoch : 77, train_loss : 0.2213 ,  val_loss : 0.3349\n",
      "epoch : 78, train_loss : 0.2211 ,  val_loss : 0.3343\n",
      "epoch : 79, train_loss : 0.2209 ,  val_loss : 0.3340\n",
      "epoch : 80, train_loss : 0.2207 ,  val_loss : 0.3333\n",
      "epoch : 81, train_loss : 0.2205 ,  val_loss : 0.3331\n",
      "epoch : 82, train_loss : 0.2203 ,  val_loss : 0.3325\n",
      "epoch : 83, train_loss : 0.2201 ,  val_loss : 0.3320\n",
      "epoch : 84, train_loss : 0.2200 ,  val_loss : 0.3318\n",
      "epoch : 85, train_loss : 0.2198 ,  val_loss : 0.3313\n",
      "epoch : 86, train_loss : 0.2195 ,  val_loss : 0.3308\n",
      "epoch : 87, train_loss : 0.2194 ,  val_loss : 0.3306\n",
      "epoch : 88, train_loss : 0.2192 ,  val_loss : 0.3302\n",
      "epoch : 89, train_loss : 0.2191 ,  val_loss : 0.3297\n",
      "epoch : 90, train_loss : 0.2190 ,  val_loss : 0.3296\n",
      "epoch : 91, train_loss : 0.2188 ,  val_loss : 0.3291\n",
      "epoch : 92, train_loss : 0.2186 ,  val_loss : 0.3288\n",
      "epoch : 93, train_loss : 0.2184 ,  val_loss : 0.3284\n",
      "epoch : 94, train_loss : 0.2183 ,  val_loss : 0.3282\n",
      "epoch : 95, train_loss : 0.2182 ,  val_loss : 0.3279\n",
      "epoch : 96, train_loss : 0.2180 ,  val_loss : 0.3275\n",
      "epoch : 97, train_loss : 0.2178 ,  val_loss : 0.3272\n",
      "epoch : 98, train_loss : 0.2177 ,  val_loss : 0.3270\n",
      "epoch : 99, train_loss : 0.2176 ,  val_loss : 0.3267\n",
      "epoch : 100, train_loss : 0.2174 ,  val_loss : 0.3264\n",
      "*************************************************************\n",
      "[Checkpoint: epoch: 100, val_loss: 0.326 \n",
      "saved on checkpoints/feedforward/checkpoint_14.pth]\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(x, y):\n",
    "    y_pred = model(x)\n",
    "    num_correct = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if(abs(y_pred[i].item() - y[i]) < 0.2):\n",
    "            num_correct += 1\n",
    "    return num_correct, x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_recall(x, y):\n",
    "    y_pred = model(x)\n",
    "    true_positive = 0\n",
    "    false_negative = 0\n",
    "    eps = 0.1\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if(y[i] >= 1.0 - eps):\n",
    "            if(y_pred[i] < 0.8):\n",
    "                false_negative += 1\n",
    "            else:\n",
    "                true_positive += 1\n",
    "\n",
    "    return true_positive, false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 84.21052631578948 %\n",
      "Recall : 94.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_corrected = 0\n",
    "total = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "for batch in test_set:\n",
    "    x, y = batch\n",
    "    a, b =check_accuracy(x, y)\n",
    "    num_corrected += a\n",
    "    total += b\n",
    "\n",
    "    a, b =check_recall(x, y)\n",
    "    tp += a\n",
    "    fn += b\n",
    "print(f'Accuracy : {num_corrected*100/total} %')\n",
    "print(f'Recall : {tp*100/(tp+fn)} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac2795493b3c8a98e1d51f9bca4fab5fcea64dcea90dee5792dd55a40a58369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
