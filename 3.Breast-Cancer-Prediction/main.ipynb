{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape : (569, 33)\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'training set shape : {df.shape}')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)\n",
    "x = df.drop(['id', 'diagnosis'], axis=1)\n",
    "y = df.iloc[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, shuffle=True, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "Y_train = Y_train.replace('M', 0)\n",
    "Y_train = Y_train.replace('B', 1)\n",
    "y_train = torch.tensor(Y_train.values.astype(np.float32), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "Y_test = Y_test.replace('M', 0)\n",
    "Y_test = Y_test.replace('B', 1)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 1.], requires_grad=True)\n",
      "tensor([[7.6910e+00, 2.5440e+01, 4.8340e+01,  ..., 5.0000e-02, 2.7900e-01,\n",
      "         1.0660e-01],\n",
      "        [1.3480e+01, 2.0820e+01, 8.8400e+01,  ..., 2.2580e-01, 2.8070e-01,\n",
      "         1.0710e-01],\n",
      "        [1.5750e+01, 2.0250e+01, 1.0260e+02,  ..., 1.4790e-01, 3.9930e-01,\n",
      "         1.0640e-01],\n",
      "        ...,\n",
      "        [1.3010e+01, 2.2220e+01, 8.2010e+01,  ..., 9.2590e-03, 2.2950e-01,\n",
      "         5.8430e-02],\n",
      "        [1.9400e+01, 1.8180e+01, 1.2720e+02,  ..., 2.2520e-01, 3.5900e-01,\n",
      "         7.7870e-02],\n",
      "        [8.9500e+00, 1.5760e+01, 5.8740e+01,  ..., 3.8460e-02, 1.6520e-01,\n",
      "         7.7220e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generates_batches(x, y, batch_size):\n",
    "    batches = []\n",
    "    num_batches = int(x.shape[0]/batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batches.append(\n",
    "                     (x[i*batch_size: (i+1)*batch_size], \n",
    "                      y[i*batch_size: (i+1)*batch_size])\n",
    "            )\n",
    "\n",
    "    if(num_batches * batch_size < x.shape[0]):\n",
    "        batches.append(\n",
    "            (x[num_batches*batch_size : x.shape[0]],\n",
    "                y[num_batches*batch_size : x.shape[0]])\n",
    "            \n",
    "        )\n",
    "    return batches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "train_set = generates_batches(x_train, y_train, 4)\n",
    "print(train_set.__len__())\n",
    "\n",
    "\n",
    "test_set = generates_batches(x_test, y_test, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(30, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = x.view(-1)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return \"feedforward\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import trainer\n",
    "\n",
    "model = feedforward()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "max_epochs = 100\n",
    "model_trainer = trainer(model, optimizer, loss_fn, train_set, test_set, max_epochs, model_name = model.model_name , when_to_stop=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train_loss : 0.3635 ,  val_loss : 0.3422\n",
      "epoch : 2, train_loss : 0.3081 ,  val_loss : 0.2636\n",
      "epoch : 3, train_loss : 0.2833 ,  val_loss : 0.2349\n",
      "epoch : 4, train_loss : 0.2651 ,  val_loss : 0.2162\n",
      "epoch : 5, train_loss : 0.2546 ,  val_loss : 0.2061\n",
      "epoch : 6, train_loss : 0.2473 ,  val_loss : 0.2000\n",
      "epoch : 7, train_loss : 0.2422 ,  val_loss : 0.1968\n",
      "epoch : 8, train_loss : 0.2373 ,  val_loss : 0.1942\n",
      "epoch : 9, train_loss : 0.2341 ,  val_loss : 0.1938\n",
      "epoch : 10, train_loss : 0.2324 ,  val_loss : 0.1945\n",
      "epoch : 11, train_loss : 0.2309 ,  val_loss : 0.1955\n",
      "epoch : 12, train_loss : 0.2295 ,  val_loss : 0.1964\n",
      "epoch : 13, train_loss : 0.2282 ,  val_loss : 0.1975\n",
      "Overfitting!\n",
      "*************************************************************\n",
      "[Checkpoint: epoch: 9, val_loss: 0.194 \n",
      "saved on checkpoints/feedforward/checkpoint_13.pth]\n",
      "*************************************************************\n",
      "Early Stopping! Overfitting\n",
      "Best Validation Loss : 0.19381077587604523, Current_Loss : 0.19749215245246887\n"
     ]
    }
   ],
   "source": [
    "model_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(x, y):\n",
    "    y_pred = model(x)\n",
    "    num_correct = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if(abs(y_pred[i].item() - y[i]) < 0.2):\n",
    "            num_correct += 1\n",
    "    acc = num_correct/x.shape[0] * 100\n",
    "    print(f'{acc:.2f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n",
      "50.00%\n",
      "50.00%\n",
      "75.00%\n",
      "100.00%\n",
      "100.00%\n",
      "75.00%\n",
      "25.00%\n",
      "100.00%\n",
      "100.00%\n",
      "100.00%\n",
      "50.00%\n",
      "75.00%\n",
      "50.00%\n",
      "100.00%\n",
      "75.00%\n",
      "75.00%\n",
      "100.00%\n",
      "100.00%\n",
      "50.00%\n",
      "75.00%\n",
      "50.00%\n",
      "50.00%\n",
      "75.00%\n",
      "75.00%\n",
      "100.00%\n",
      "100.00%\n",
      "50.00%\n",
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in test_set:\n",
    "    x, y = batch\n",
    "    check_accuracy(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac2795493b3c8a98e1d51f9bca4fab5fcea64dcea90dee5792dd55a40a58369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
