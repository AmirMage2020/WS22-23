{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape : (569, 33)\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'training set shape : {df.shape}')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 32', axis=1)\n",
    "x = df.drop(['id', 'diagnosis'], axis=1)\n",
    "y = df.iloc[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, shuffle=True, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(X_train.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "Y_train = Y_train.replace('M', 0)\n",
    "Y_train = Y_train.replace('B', 1)\n",
    "y_train = torch.tensor(Y_train.values.astype(np.float32), dtype=torch.float, requires_grad=True)\n",
    "\n",
    "x_test = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32, requires_grad=True)\n",
    "Y_test = Y_test.replace('M', 0)\n",
    "Y_test = Y_test.replace('B', 1)\n",
    "y_test = torch.tensor(Y_test.values.astype(np.float32), dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0.], requires_grad=True)\n",
      "tensor([[1.8220e+01, 1.8870e+01, 1.1870e+02,  ..., 1.7760e-01, 2.8120e-01,\n",
      "         8.1980e-02],\n",
      "        [1.3640e+01, 1.6340e+01, 8.7210e+01,  ..., 8.5860e-02, 2.3460e-01,\n",
      "         8.0250e-02],\n",
      "        [9.6680e+00, 1.8100e+01, 6.1060e+01,  ..., 2.5000e-02, 3.0570e-01,\n",
      "         7.8750e-02],\n",
      "        ...,\n",
      "        [1.3380e+01, 3.0720e+01, 8.6340e+01,  ..., 7.7630e-02, 2.1960e-01,\n",
      "         7.6750e-02],\n",
      "        [2.1560e+01, 2.2390e+01, 1.4200e+02,  ..., 2.2160e-01, 2.0600e-01,\n",
      "         7.1150e-02],\n",
      "        [2.3210e+01, 2.6970e+01, 1.5350e+02,  ..., 2.5930e-01, 3.1030e-01,\n",
      "         8.6770e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generates_batches(x, y, batch_size):\n",
    "    batches = []\n",
    "    num_batches = int(x.shape[0]/batch_size)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batches.append(\n",
    "                     (x[i*batch_size: (i+1)*batch_size], \n",
    "                      y[i*batch_size: (i+1)*batch_size])\n",
    "            )\n",
    "\n",
    "    if(num_batches * batch_size < x.shape[0]):\n",
    "        batches.append(\n",
    "            (x[num_batches*batch_size : x.shape[0]],\n",
    "                y[num_batches*batch_size : x.shape[0]])\n",
    "            \n",
    "        )\n",
    "    return batches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "train_set = generates_batches(x_train, y_train, 4)\n",
    "print(train_set.__len__())\n",
    "\n",
    "\n",
    "test_set = generates_batches(x_test, y_test, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class feedforward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(30, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = x.view(-1)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        return \"feedforward\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Trainer import trainer\n",
    "\n",
    "model = feedforward()\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "max_epochs = 100\n",
    "model_trainer = trainer(model, optimizer, loss_fn, train_set, test_set, max_epochs, model_name = model.model_name , when_to_stop=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, train_loss : 4.8161 ,  val_loss : 3.9942\n",
      "epoch : 2, train_loss : 0.3844 ,  val_loss : 0.3288\n",
      "epoch : 3, train_loss : 0.3344 ,  val_loss : 0.2717\n",
      "epoch : 4, train_loss : 0.2977 ,  val_loss : 0.2348\n",
      "epoch : 5, train_loss : 0.2743 ,  val_loss : 0.2139\n",
      "epoch : 6, train_loss : 0.2598 ,  val_loss : 0.2006\n",
      "epoch : 7, train_loss : 0.2515 ,  val_loss : 0.1914\n",
      "epoch : 8, train_loss : 0.2461 ,  val_loss : 0.1844\n",
      "epoch : 9, train_loss : 0.2419 ,  val_loss : 0.1791\n",
      "epoch : 10, train_loss : 0.2384 ,  val_loss : 0.1749\n",
      "epoch : 11, train_loss : 0.2356 ,  val_loss : 0.1715\n",
      "epoch : 12, train_loss : 0.2332 ,  val_loss : 0.1686\n",
      "epoch : 13, train_loss : 0.2312 ,  val_loss : 0.1662\n",
      "epoch : 14, train_loss : 0.2296 ,  val_loss : 0.1640\n",
      "epoch : 15, train_loss : 0.2282 ,  val_loss : 0.1620\n",
      "epoch : 16, train_loss : 0.2270 ,  val_loss : 0.1603\n",
      "epoch : 17, train_loss : 0.2260 ,  val_loss : 0.1588\n",
      "epoch : 18, train_loss : 0.2251 ,  val_loss : 0.1575\n",
      "epoch : 19, train_loss : 0.2243 ,  val_loss : 0.1563\n",
      "epoch : 20, train_loss : 0.2236 ,  val_loss : 0.1553\n",
      "epoch : 21, train_loss : 0.2230 ,  val_loss : 0.1543\n",
      "epoch : 22, train_loss : 0.2225 ,  val_loss : 0.1534\n",
      "epoch : 23, train_loss : 0.2221 ,  val_loss : 0.1527\n",
      "epoch : 24, train_loss : 0.2217 ,  val_loss : 0.1520\n",
      "epoch : 25, train_loss : 0.2213 ,  val_loss : 0.1514\n",
      "epoch : 26, train_loss : 0.2211 ,  val_loss : 0.1508\n",
      "epoch : 27, train_loss : 0.2209 ,  val_loss : 0.1502\n",
      "epoch : 28, train_loss : 0.2208 ,  val_loss : 0.1497\n",
      "epoch : 29, train_loss : 0.2207 ,  val_loss : 0.1492\n",
      "epoch : 30, train_loss : 0.2205 ,  val_loss : 0.1489\n",
      "epoch : 31, train_loss : 0.2203 ,  val_loss : 0.1486\n",
      "epoch : 32, train_loss : 0.2199 ,  val_loss : 0.1485\n",
      "epoch : 33, train_loss : 0.2198 ,  val_loss : 0.1482\n",
      "epoch : 34, train_loss : 0.2196 ,  val_loss : 0.1481\n",
      "epoch : 35, train_loss : 0.2193 ,  val_loss : 0.1480\n",
      "epoch : 36, train_loss : 0.2191 ,  val_loss : 0.1479\n",
      "epoch : 37, train_loss : 0.2188 ,  val_loss : 0.1478\n",
      "epoch : 38, train_loss : 0.2184 ,  val_loss : 0.1476\n",
      "epoch : 39, train_loss : 0.2180 ,  val_loss : 0.1475\n",
      "epoch : 40, train_loss : 0.2176 ,  val_loss : 0.1475\n",
      "epoch : 41, train_loss : 0.2173 ,  val_loss : 0.1473\n",
      "epoch : 42, train_loss : 0.2173 ,  val_loss : 0.1471\n",
      "epoch : 43, train_loss : 0.2171 ,  val_loss : 0.1470\n",
      "epoch : 44, train_loss : 0.2170 ,  val_loss : 0.1469\n",
      "epoch : 45, train_loss : 0.2169 ,  val_loss : 0.1467\n",
      "epoch : 46, train_loss : 0.2168 ,  val_loss : 0.1465\n",
      "epoch : 47, train_loss : 0.2167 ,  val_loss : 0.1464\n",
      "epoch : 48, train_loss : 0.2167 ,  val_loss : 0.1462\n",
      "epoch : 49, train_loss : 0.2166 ,  val_loss : 0.1461\n",
      "epoch : 50, train_loss : 0.2166 ,  val_loss : 0.1459\n",
      "*************************************************************\n",
      "[Checkpoint: epoch: 50, val_loss: 0.146 \n",
      "saved on checkpoints/feedforward/checkpoint_12.pth]\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(x, y):\n",
    "    y_pred = model(x)\n",
    "    num_correct = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if(abs(y_pred[i].item() - y[i]) < 0.2):\n",
    "            num_correct += 1\n",
    "    acc = num_correct/x.shape[0] * 100\n",
    "    print(f'{acc:.2f}%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00%\n",
      "0.00%\n",
      "100.00%\n",
      "0.00%\n",
      "50.00%\n",
      "25.00%\n",
      "50.00%\n",
      "0.00%\n",
      "0.00%\n",
      "50.00%\n",
      "0.00%\n",
      "75.00%\n",
      "50.00%\n",
      "25.00%\n",
      "75.00%\n",
      "25.00%\n",
      "50.00%\n",
      "50.00%\n",
      "0.00%\n",
      "50.00%\n",
      "50.00%\n",
      "25.00%\n",
      "50.00%\n",
      "50.00%\n",
      "50.00%\n",
      "50.00%\n",
      "25.00%\n",
      "75.00%\n",
      "50.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in test_set:\n",
    "    x, y = batch\n",
    "    check_accuracy(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac2795493b3c8a98e1d51f9bca4fab5fcea64dcea90dee5792dd55a40a58369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
