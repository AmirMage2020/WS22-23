{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import Generator, Discriminator, weight_init\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from DataLoading import mnistLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = mnistLoader()\n",
    "train_loader, val_loader = data_loader.train_val_loader(16, 16, shuffle=True, split = 0.8, ratio = 1)\n",
    "test_loader = data_loader.test_loader(16, shuffle=False, ratio = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = enumerate(train_loader, 0)\n",
    "\n",
    "i, batch = iterator.__next__()\n",
    "new_loader = [batch]\n",
    "it2 = enumerate(new_loader, 0)\n",
    "i, batch2 = it2.__next__()\n",
    "print(i)\n",
    "print(batch2)\n",
    "x, _ = batch2\n",
    "x = [x]\n",
    "x.append(torch.randn(16))\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(x):\n",
    "\n",
    "    x = x.clone().detach()\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    for i in range(x.shape[0]):\n",
    "        fig.add_subplot(3,int(x.shape[0]/3) + 1, i+1)\n",
    "        image = torch.squeeze(x[i]).numpy() \n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(3, 1, 28, 28)\n",
    "dd = Discriminator(1, 32)\n",
    "dd(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "nzd, ngf, ndf = 64, 64, 64\n",
    "MAX_EPOCHS = 5\n",
    "real_labels = torch.ones(BATCH_SIZE)\n",
    "fake_labels = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "test_set = torch.randn(16, nzd, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator(1, ndf)\n",
    "netG = Generator(nzd, ngf, 1)\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "netD.to(device)\n",
    "netG.to(device)\n",
    "\n",
    "netD.apply(weight_init)\n",
    "netG.apply(weight_init)\n",
    "num_epochs = 10\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr =0.001,  betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        real_img, _ = data\n",
    "        netD.zero_grad()\n",
    "        output_real = netD(real_img)\n",
    "        errD_real = loss_fn(output_real, real_labels)\n",
    "        errD_real.backward()\n",
    "\n",
    "        D_x = output_real.mean().item()\n",
    "\n",
    "\n",
    "        noise = torch.randn(BATCH_SIZE, nzd, 1, 1)\n",
    "        fake_img = netG(noise)\n",
    "        output_fake = netD(fake_img.detach())\n",
    "        errD_fake = loss_fn(output_fake, fake_labels)\n",
    "\n",
    "        D_G_z1 = output_fake.mean().item()\n",
    "\n",
    "        errD_fake.backward()\n",
    "        errD = errD_fake + errD_real\n",
    "        optimizerD.step()\n",
    "\n",
    "        ###############################\n",
    "\n",
    "        netG.zero_grad()\n",
    "        output_fake = netD(fake_img)\n",
    "        errG = loss_fn(output_fake, real_labels)\n",
    "\n",
    "        D_G_z2 = output_fake.mean().item()\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        ###############################\n",
    "\n",
    "        if i%50 == 0:\n",
    "            netG.eval()\n",
    "            netD.eval()\n",
    "            with torch.no_grad():\n",
    "                img_fake = netG(test_set)\n",
    "                output_fake = netD(img_fake).mean().item()\n",
    "                print(f'epoch: {epoch}, iter: {i}, Loss_D: {errD.item()}, Loss_G: {errG.item()}, \\n test_set: {output_fake}')\n",
    "                visualize(img_fake)\n",
    "            netG.train()\n",
    "            netD.train()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ac2795493b3c8a98e1d51f9bca4fab5fcea64dcea90dee5792dd55a40a58369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
